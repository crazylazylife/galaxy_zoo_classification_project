{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxy_zoo_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Banz_LkCZjiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpkCuYEdbp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ../root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyYiKrh5df7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "%cd .kaggle\n",
        "uploading = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZkDpPszduPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ../../content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfiMWqEYan6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKQN1tvt-k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip training_solutions_rev1.zip\n",
        "!unzip images_training_rev1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTjqN2NkPxzc",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------\n",
        "Beginning preprocessing, developing and training the ResNet model for the task of classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxuWU-oP_ml",
        "colab_type": "code",
        "outputId": "dab5dd50-5942-4a81-a229-e3cc86c87d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, ZeroPadding2D, Flatten, AveragePooling2D, MaxPooling2D, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout\n",
        "from keras.activations import relu, softmax\n",
        "from keras.models import Model, load_model\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "import keras.backend as K\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxYYvELfm7Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the hyperparameters\n",
        "num_epochs = 20\n",
        "b_size = 32\n",
        "set_size = 20000\n",
        "final_x = 112\n",
        "final_y = 112\n",
        "split_ratio = 0.8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BezGtAkSB5tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "This part processes the images by first cropping them to 312x312 size and then resizing them\n",
        "to final_x*final_y images. \n",
        "First we read in some of the values in training_solutions_rev1.csv as defined by the set_size.\n",
        "'''\n",
        "Y_full = pd.read_csv('training_solutions_rev1.csv', skiprows=None, nrows=set_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB7om4FLE4vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train, Y_test = train_test_split(Y_full, test_size=(1 - split_ratio))\n",
        "train_l = len(Y_train)\n",
        "test_l = len(Y_test)\n",
        "del Y_full\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjw0EjUFGT01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.zeros((train_l, final_x, final_y, 3))\n",
        "i = 0\n",
        "for id in Y_train[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_x, final_y))  \n",
        "  X_train[i] = img\n",
        "  i+=1\n",
        "  \n",
        "del train_l\n",
        "gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzAX1TMGuM_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.zeros((test_l, final_x, final_y, 3))\n",
        "i = 0  \n",
        "for id in Y_test[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_x, final_y))  \n",
        "  X_test[i] = img\n",
        "  i+=1\n",
        "  \n",
        "\n",
        "del test_l\n",
        "gc.collect()\n",
        "\n",
        "Y_train.drop(columns=[\"GalaxyID\"])\n",
        "Y_test.drop(columns=[\"GalaxyID\"])\n",
        "\n",
        "'''\n",
        "At the end of this cell we have four important variables, namely: \n",
        "X_train and X_test --> containing the training and testing images as lists of images.\n",
        "Y_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0yvCB-exWf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the ResNet Architecture\n",
        "\n",
        "class ResNet:\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def identity_block(self, X, f_shape, n_filters, stage, block_name):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def convolutional_block(self, X, f_shape, n_filters, stage, block_name, s=2):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    s -> denoting the stride to be used\n",
        "    '''\n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(s, s), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Convolution for the shortcut\n",
        "    X_skip = Conv2D(filters=f2, kernel_size=(1, 1), strides=(s, s), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_1\", kernel_initializer=glorot_uniform(seed=0))(X_skip)\n",
        "    X_skip = BatchNormalization(axis=3, name= \"batchnorm\"+str(stage)+block_name+\"_branch_1\")(X_skip)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def ResNet18(self, input_shape=(final_x, final_y, 3), classes=38):\n",
        "    '''\n",
        "    Defining the ResNet18 Architecture used\n",
        "    \n",
        "    Conv1 -> 7 X 7, 64, stride = 2, Output = (112 X 112)\n",
        "    \n",
        "    Conv2 -> 3 X 3 MaxPool, stride=2\n",
        "             [3 X 3, 64] * 2\n",
        "             \n",
        "    Conv3 -> [3 X 3, 128] * 2\n",
        "    \n",
        "    Conv4 -> [3 X 3, 256] * 2\n",
        "    \n",
        "    Conv5 -> [3 X 3, 512] * 2\n",
        "    '''\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    #Conv1\n",
        "    X = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=\"batchnorm_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Conv2\n",
        "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"b\")\n",
        "    \n",
        "    #Conv3\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"b\")\n",
        "    \n",
        "    #Conv4\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"b\")\n",
        "    \n",
        "    #Conv5\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"b\")\n",
        "    \n",
        "    #Final Dense Layers\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    #Create the model\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"ResNet18\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFn8ZdZceZ7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing and Compiling the model\n",
        "Resnet18 = ResNet()\n",
        "model = Resnet18.ResNet18(input_shape=(final_x, final_y, 3), classes=38)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "train_tensorboard = TensorBoard(log_dir=\"./logs/train\", histogram_freq = 0, write_graph  =True, write_images = True)\n",
        "test_tensorboard = TensorBoard(log_dir=\"./logs/test\", histogram_freq = 0, write_graph  =True, write_images = False)\n",
        "checkpointer = ModelCheckpoint(filepath='tmp/weights_resnet18.hdf5', verbose=1, save_best_only = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7BI7EYMJZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Traing the model on the training data\n",
        "model.fit(X_train, Y_train, epochs = num_epochs, batch_size = b_size, verbose = 1, callbacks = [checkpointer, train_tensorboard])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qm6owX8OI8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluating the data on the test set\n",
        "prediction = model.evaluate(X_test, Y_test, batch_size = b_size, verbose = 1)\n",
        "print(\"Test Loss: \"+str(prediction[0]))\n",
        "print(\"Test Accuracy: \"+str(prediction[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O9h5RAjiQra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}