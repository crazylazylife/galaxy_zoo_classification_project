{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "galaxy_zoo_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazylazylife/galaxy_zoo_classification_project/blob/master/galaxy_zoo_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Banz_LkCZjiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpkCuYEdbp4",
        "colab_type": "code",
        "outputId": "ac551e52-041b-4424-cdbe-a78ad28a3261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../root"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyYiKrh5df7g",
        "colab_type": "code",
        "outputId": "0c5c9eb3-cf0b-40b0-ca3b-39ed50969065",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "!mkdir .kaggle\n",
        "%cd .kaggle\n",
        "uploading = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51973a6e-97e3-4b2e-9d7a-fa2ebf59ddec\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-51973a6e-97e3-4b2e-9d7a-fa2ebf59ddec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZkDpPszduPB",
        "colab_type": "code",
        "outputId": "167a4860-4889-4724-fcf7-28bfab78e321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../../content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfiMWqEYan6k",
        "colab_type": "code",
        "outputId": "398081a8-479b-4c24-f3a2-3e86c1f471b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading all_ones_benchmark.zip to /content\n",
            "  0% 0.00/265k [00:00<?, ?B/s]\n",
            "100% 265k/265k [00:00<00:00, 36.3MB/s]\n",
            "Downloading all_zeros_benchmark.zip to /content\n",
            "  0% 0.00/265k [00:00<?, ?B/s]\n",
            "100% 265k/265k [00:00<00:00, 83.4MB/s]\n",
            "Downloading central_pixel_benchmark.zip to /content\n",
            "  0% 0.00/520k [00:00<?, ?B/s]\n",
            "100% 520k/520k [00:00<00:00, 70.9MB/s]\n",
            "Downloading images_training_rev1.zip to /content\n",
            " 99% 781M/792M [00:15<00:00, 62.4MB/s]\n",
            "100% 792M/792M [00:15<00:00, 53.3MB/s]\n",
            "Downloading images_test_rev1.zip to /content\n",
            " 99% 1.00G/1.01G [00:20<00:00, 70.4MB/s]\n",
            "100% 1.01G/1.01G [00:21<00:00, 51.4MB/s]\n",
            "Downloading training_solutions_rev1.zip to /content\n",
            "100% 4.63M/4.63M [00:00<00:00, 19.0MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKQN1tvt-k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip training_solutions_rev1.zip\n",
        "!unzip images_training_rev1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTjqN2NkPxzc",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------\n",
        "Beginning preprocessing, developing and training the ResNet model for the task of classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxuWU-oP_ml",
        "colab_type": "code",
        "outputId": "58310573-d0f0-44e0-a697-6d517fd3911d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, ZeroPadding2D, Flatten, AveragePooling2D, MaxPooling2D, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout\n",
        "from keras.activations import relu, softmax\n",
        "from keras.models import Model, load_model\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "import keras.backend as K\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_RAaOM8glRP",
        "colab_type": "code",
        "outputId": "5ddce9bd-4e8a-4628-87dc-958dc38bb8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Inputing the instance of training running\n",
        "check = int(input(\"Enter training instance: \"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter training instance: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxYYvELfm7Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the hyperparameters\n",
        "num_epochs = 20   #200 is too much. 20 is fine.\n",
        "batch_size = 32\n",
        "set_size = 5000\n",
        "final_width = 224\n",
        "final_height = 224\n",
        "split_ratio = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pEKU86wc_RR",
        "colab_type": "code",
        "outputId": "53f2d61e-0207-4315-f461-e0ee6aa7ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "'''\n",
        "This part processes the images by first cropping them to 312x312 size and then resizing them\n",
        "to final_width*final_height images. \n",
        "First we read in some of the values in training_solutions_rev1.csv as defined by the set_size.\n",
        "'''\n",
        "Y_full = pd.read_csv('training_solutions_rev1.csv')\n",
        "Y_full = Y_full[set_size*(check-1):set_size*(check)]\n",
        "print(Y_full.head())\n",
        "Y_train, Y_test = train_test_split(Y_full, test_size=(1 - split_ratio))\n",
        "train_l = len(Y_train)\n",
        "test_l = len(Y_test)\n",
        "del Y_full\n",
        "gc.collect()\n",
        "\n",
        "X_train = np.zeros((train_l, final_width, final_height, 3))\n",
        "i = 0\n",
        "for id in Y_train[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_width, final_height))  \n",
        "  X_train[i] = img\n",
        "  i+=1\n",
        "  \n",
        "del train_l\n",
        "gc.collect()\n",
        "\n",
        "X_test = np.zeros((test_l, final_width, final_height, 3))\n",
        "i = 0  \n",
        "for id in Y_test[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_width, final_height))  \n",
        "  X_test[i] = img\n",
        "  i+=1\n",
        "  \n",
        "\n",
        "del test_l\n",
        "gc.collect()\n",
        "\n",
        "Y_train.drop(columns=[\"GalaxyID\"])\n",
        "Y_test.drop(columns=[\"GalaxyID\"])\n",
        "\n",
        "'''\n",
        "At the end of this cell we have four important variables, namely: \n",
        "X_train and X_test --> containing the training and testing images as lists of images.\n",
        "Y_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       GalaxyID  Class1.1  Class1.2  ...  Class11.4  Class11.5  Class11.6\n",
            "15000    322068  0.898048  0.101952  ...   0.000000        0.0   0.000000\n",
            "15001    322105  0.039816  0.952036  ...   0.000000        0.0   0.121735\n",
            "15002    322110  0.818857  0.105035  ...   0.000000        0.0   0.000000\n",
            "15003    322167  0.013495  0.968924  ...   0.069252        0.0   0.000000\n",
            "15004    322178  0.786106  0.213894  ...   0.000000        0.0   0.000000\n",
            "\n",
            "[5 rows x 38 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAt the end of this cell we have four important variables, namely: \\nX_train and X_test --> containing the training and testing images as lists of images.\\nY_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0yvCB-exWf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the ResNet Architecture\n",
        "\n",
        "class ResNet:\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def identity_block(self, X, f_shape, n_filters, stage, block_name):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def convolutional_block(self, X, f_shape, n_filters, stage, block_name, s=2):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    s -> denoting the stride to be used\n",
        "    '''\n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(s, s), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Convolution for the shortcut\n",
        "    X_skip = Conv2D(filters=f2, kernel_size=(1, 1), strides=(s, s), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_1\", kernel_initializer=glorot_uniform(seed=0))(X_skip)\n",
        "    X_skip = BatchNormalization(axis=3, name= \"batchnorm\"+str(stage)+block_name+\"_branch_1\")(X_skip)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def ResNet18(self, input_shape=(224, 224, 3), classes=38):\n",
        "    '''\n",
        "    Defining the ResNet18 Architecture used\n",
        "    \n",
        "    Conv1 -> 7 X 7, 64, stride = 2, Output = (112 X 112)\n",
        "    \n",
        "    Conv2 -> 3 X 3 MaxPool, stride=2\n",
        "             [3 X 3, 64] * 2\n",
        "             \n",
        "    Conv3 -> [3 X 3, 128] * 2\n",
        "    \n",
        "    Conv4 -> [3 X 3, 256] * 2\n",
        "    \n",
        "    Conv5 -> [3 X 3, 512] * 2\n",
        "    '''\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    #Conv1\n",
        "    X = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=\"batchnorm_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Conv2\n",
        "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"b\")\n",
        "    \n",
        "    #Conv3\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"b\")\n",
        "    \n",
        "    #Conv4\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"b\")\n",
        "    \n",
        "    #Conv5\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"b\")\n",
        "    \n",
        "    #Final Dense Layers\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    #Create the model\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"ResNet18\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFn8ZdZceZ7w",
        "colab_type": "code",
        "outputId": "32348876-9ea7-4d21-be1a-973fb1f9f217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#Initializing and Compiling the model\n",
        "Resnet18 = ResNet()\n",
        "model = Resnet18.ResNet18(input_shape=(224, 224, 3), classes=38)\n",
        "if (check == 1):\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "else:\n",
        "  print(\"Loading pretrained model...\")\n",
        "  model = load_model(\"trained_resnet18.h5\")\n",
        "  \n",
        "train_tensorboard = TensorBoard(log_dir=\"./logs/train_\"+str(check), histogram_freq = 0, write_graph  =True, write_images = True)\n",
        "checkpointer = ModelCheckpoint(filepath='tmp/weights_resnet18.hdf5', verbose=1, save_best_only = True)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Loading pretrained model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7BI7EYMJZu",
        "colab_type": "code",
        "outputId": "25f7f315-8f17-4eb5-e972-b3cf88c58355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "source": [
        "#Traing the model on the training data\n",
        "model.fit(X_train, Y_train, epochs = num_epochs, batch_size = batch_size, verbose = 1, callbacks = [checkpointer, train_tensorboard], validation_data = (X_test, Y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 81.04539\n",
            "Epoch 2/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 81.04539\n",
            "Epoch 3/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 81.04539\n",
            "Epoch 4/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 81.04539\n",
            "Epoch 5/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 81.04539\n",
            "Epoch 6/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 81.04539\n",
            "Epoch 7/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 81.04539\n",
            "Epoch 8/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 81.04539\n",
            "Epoch 9/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 81.04539\n",
            "Epoch 10/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 81.04539\n",
            "Epoch 11/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 81.04539\n",
            "Epoch 12/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 81.04539\n",
            "Epoch 13/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 81.04539\n",
            "Epoch 14/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 81.04539\n",
            "Epoch 15/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 81.04539\n",
            "Epoch 16/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 81.04539\n",
            "Epoch 17/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 81.04539\n",
            "Epoch 18/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 81.04539\n",
            "Epoch 19/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 81.04539\n",
            "Epoch 20/20\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 81.6818 - acc: 1.0000 - val_loss: 81.0454 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 81.04539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe22cb136a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZiod9azMmxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the trained model for further training on the next batch\n",
        "model.save(\"trained_resnet18.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qm6owX8OI8K",
        "colab_type": "code",
        "outputId": "ea7790f2-57b3-48f8-c9bd-b2c97ec4a2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Evaluating the data on the test set\n",
        "test_tensorboard = TensorBoard(log_dir=\"./logs/test_\"+str(check), histogram_freq = 0, write_graph  =True, write_images = False)\n",
        "#test_tensorboard not working with model.evaluate. Gonna change it later.\n",
        "prediction = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 1)\n",
        "print(\"Test Loss: \"+str(prediction[0]))\n",
        "print(\"Test Accuracy: \"+str(prediction[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "Test Loss: 81.04538555908204\n",
            "Test Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SIHbm2hhJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}