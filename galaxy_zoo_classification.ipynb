{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "galaxy_zoo_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazylazylife/galaxy_zoo_classification_project/blob/master/galaxy_zoo_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Banz_LkCZjiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpkCuYEdbp4",
        "colab_type": "code",
        "outputId": "883f04e8-ae56-4d63-a3ff-6efee9eb1842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../root"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyYiKrh5df7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "%cd .kaggle\n",
        "uploading = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZkDpPszduPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ../../content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfiMWqEYan6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKQN1tvt-k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip training_solutions_rev1.zip\n",
        "!unzip images_training_rev1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTjqN2NkPxzc",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------\n",
        "Beginning preprocessing, developing and training the ResNet model for the task of classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxuWU-oP_ml",
        "colab_type": "code",
        "outputId": "c5358d79-4dc1-4ec5-dad1-36516d1c70b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, ZeroPadding2D, Flatten, AveragePooling2D, MaxPooling2D, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout\n",
        "from keras.activations import relu, softmax\n",
        "from keras.models import Model, load_model\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "import keras.backend as K\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_RAaOM8glRP",
        "colab_type": "code",
        "outputId": "5ddce9bd-4e8a-4628-87dc-958dc38bb8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Inputing the instance of training running\n",
        "check = int(input(\"Enter training instance: \"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter training instance: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxYYvELfm7Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the hyperparameters\n",
        "num_epochs = 20   #200 is too much. 20 is fine.\n",
        "batch_size = 32\n",
        "set_size = 5000\n",
        "final_width = 224\n",
        "final_height = 224\n",
        "split_ratio = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pEKU86wc_RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This part processes the images by first cropping them to 312x312 size and then resizing them\n",
        "to final_width*final_height images. \n",
        "First we read in some of the values in training_solutions_rev1.csv as defined by the set_size.\n",
        "'''\n",
        "Y_full = pd.read_csv('training_solutions_rev1.csv')\n",
        "Y_full = Y_full[set_size*(check-1):set_size*(check)]\n",
        "print(Y_full.head())\n",
        "Y_train, Y_test = train_test_split(Y_full, test_size=(1 - split_ratio))\n",
        "train_l = len(Y_train)\n",
        "test_l = len(Y_test)\n",
        "del Y_full\n",
        "gc.collect()\n",
        "\n",
        "X_train = np.zeros((train_l, final_width, final_height, 3))\n",
        "i = 0\n",
        "for id in Y_train[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_width, final_height))  \n",
        "  X_train[i] = img\n",
        "  i+=1\n",
        "  \n",
        "del train_l\n",
        "gc.collect()\n",
        "\n",
        "X_test = np.zeros((test_l, final_width, final_height, 3))\n",
        "i = 0  \n",
        "for id in Y_test[\"GalaxyID\"]:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (final_width, final_height))  \n",
        "  X_test[i] = img\n",
        "  i+=1\n",
        "  \n",
        "\n",
        "del test_l\n",
        "gc.collect()\n",
        "\n",
        "Y_train.drop(columns=[\"GalaxyID\"])\n",
        "Y_test.drop(columns=[\"GalaxyID\"])\n",
        "\n",
        "'''\n",
        "At the end of this cell we have four important variables, namely: \n",
        "X_train and X_test --> containing the training and testing images as lists of images.\n",
        "Y_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0yvCB-exWf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the ResNet Architecture\n",
        "\n",
        "class ResNet:\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def identity_block(self, X, f_shape, n_filters, stage, block_name):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def convolutional_block(self, X, f_shape, n_filters, stage, block_name, s=2):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    s -> denoting the stride to be used\n",
        "    '''\n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(s, s), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Convolution for the shortcut\n",
        "    X_skip = Conv2D(filters=f2, kernel_size=(1, 1), strides=(s, s), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_1\", kernel_initializer=glorot_uniform(seed=0))(X_skip)\n",
        "    X_skip = BatchNormalization(axis=3, name= \"batchnorm\"+str(stage)+block_name+\"_branch_1\")(X_skip)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def ResNet18(self, input_shape=(224, 224, 3), classes=38):\n",
        "    '''\n",
        "    Defining the ResNet18 Architecture used\n",
        "    \n",
        "    Conv1 -> 7 X 7, 64, stride = 2, Output = (112 X 112)\n",
        "    \n",
        "    Conv2 -> 3 X 3 MaxPool, stride=2\n",
        "             [3 X 3, 64] * 2\n",
        "             \n",
        "    Conv3 -> [3 X 3, 128] * 2\n",
        "    \n",
        "    Conv4 -> [3 X 3, 256] * 2\n",
        "    \n",
        "    Conv5 -> [3 X 3, 512] * 2\n",
        "    '''\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    #Conv1\n",
        "    X = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=\"batchnorm_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Conv2\n",
        "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"b\")\n",
        "    \n",
        "    #Conv3\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"b\")\n",
        "    \n",
        "    #Conv4\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"b\")\n",
        "    \n",
        "    #Conv5\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"b\")\n",
        "    \n",
        "    #Final Dense Layers\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    #Create the model\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"ResNet18\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFn8ZdZceZ7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing and Compiling the model\n",
        "Resnet18 = ResNet()\n",
        "model = Resnet18.ResNet18(input_shape=(224, 224, 3), classes=38)\n",
        "if (check == 1):\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "else:\n",
        "  print(\"Loading pretrained model...\")\n",
        "  model = load_model(\"trained_resnet18.h5\")\n",
        "  \n",
        "train_tensorboard = TensorBoard(log_dir=\"./logs/train_\"+str(check), histogram_freq = 0, write_graph  =True, write_images = True)\n",
        "checkpointer = ModelCheckpoint(filepath='tmp/weights_resnet18.hdf5', verbose=1, save_best_only = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7BI7EYMJZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Traing the model on the training data\n",
        "model.fit(X_train, Y_train, epochs = num_epochs, batch_size = batch_size, verbose = 1, callbacks = [checkpointer, train_tensorboard], validation_data = (X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZiod9azMmxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the trained model for further training on the next batch\n",
        "model.save(\"trained_resnet18.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qm6owX8OI8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluating the data on the test set\n",
        "test_tensorboard = TensorBoard(log_dir=\"./logs/test_\"+str(check), histogram_freq = 0, write_graph  =True, write_images = False)\n",
        "#test_tensorboard not working with model.evaluate. Gonna change it later.\n",
        "prediction = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 1)\n",
        "print(\"Test Loss: \"+str(prediction[0]))\n",
        "print(\"Test Accuracy: \"+str(prediction[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SIHbm2hhJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploading = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s5vpzHTvgHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Resnet18 = ResNet()\n",
        "model = Resnet18.ResNet18(input_shape=(224, 224, 3), classes=38)\n",
        "model = load_model(\"trained_resnet18.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y7Dw-Y7uyW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"upload the image to check predictions\")\n",
        "uploading = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2XC21MpvO1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = input(\"enter the name of the image \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1McTWm-tm4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(name+'.jpg')\n",
        "img = img[56:368, 56:368]\n",
        "img = cv2.resize(img, (224, 224))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAIXzwaIv7d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([[np.array(img)]])\n",
        "np.savetxt(name+'.txt', pred, fmt='%.18f', delimiter=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_acza9-exMi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}