{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of galaxy_zoo_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fackor/galaxy_zoo_classification_project/blob/master/Galaxy_zoo_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Banz_LkCZjiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpkCuYEdbp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8eabe47d-211b-499b-ac81-3c58ab6491d0"
      },
      "source": [
        "%cd ../root"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyYiKrh5df7g",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b27e0af9-993e-4646-9829-b73142fcc7e2"
      },
      "source": [
        "!mkdir .kaggle\n",
        "%cd .kaggle\n",
        "uploading = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f8cd23dc-fff1-4829-89b7-d5b7be0f9298\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f8cd23dc-fff1-4829-89b7-d5b7be0f9298\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZkDpPszduPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dddd1db5-8834-4eaa-cc71-ee033624bdb4"
      },
      "source": [
        "%cd ../../content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfiMWqEYan6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ae9151d0-afc0-44c4-9c28-dc37126e7906"
      },
      "source": [
        "!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "all_ones_benchmark.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "all_zeros_benchmark.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "central_pixel_benchmark.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "images_training_rev1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "images_test_rev1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "training_solutions_rev1.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKQN1tvt-k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "53d296ad-2bb6-4ad0-c148-30361e4272cc"
      },
      "source": [
        "!unzip training_solutions_rev1.zip\n",
        "!unzip images_training_rev1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  training_solutions_rev1.zip\n",
            "replace training_solutions_rev1.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Archive:  images_training_rev1.zip\n",
            "replace images_training_rev1/100008.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTjqN2NkPxzc",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------\n",
        "Beginning preprocessing, developing and training the ResNet model for the task of classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxuWU-oP_ml",
        "colab_type": "code",
        "outputId": "6b579592-835d-4b25-9c0d-8f3026acd2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, ZeroPadding2D, Flatten, AveragePooling2D, MaxPooling2D, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Dropout\n",
        "from keras.activations import relu, softmax\n",
        "from keras.models import Model, load_model\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "import keras.backend as K\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BezGtAkSB5tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "This part processes the images by first cropping them to 312x312 size and then resizing them\n",
        "to 224x224 images. Here we maintain a label for each image that will be used later to help split data into \n",
        "training and test sets.\n",
        "'''\n",
        "set_size = 1000\n",
        "X_full = {}\n",
        "\n",
        "Y_full = pd.read_csv('training_solutions_rev1.csv')\n",
        "Y_full = Y_full.loc[:set_size]\n",
        "\n",
        "i = 0\n",
        "for id in Y_full[\"GalaxyID\"].tolist():\n",
        "  if i > set_size:\n",
        "    break\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  img = cv2.imread(name)\n",
        "  img = img[56:368, 56:368]\n",
        "  img = cv2.resize(img, (224, 224))\n",
        "  X_full[name] = img\n",
        "  i += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB7om4FLE4vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This part conttains the declarations for the split_ratio variable,\n",
        "which controls the ratio in which the training and test are split\n",
        "'''   \n",
        "split_ratio = 0.8\n",
        "\n",
        "\n",
        "'''\n",
        "This part reads in the csv files and splits it into training and test sets, we use the train_test_split() method from \n",
        "the sklearn module.\n",
        "'''\n",
        "\n",
        "Y_train, Y_test = train_test_split(Y_full, test_size=(1 - split_ratio))\n",
        "\n",
        "'''\n",
        "We now extract the GalaxyID labels from the Y_train and Y_test dataframes and use these labels to create our \n",
        "X_train and X_test variables containg the images.\n",
        "'''\n",
        "train_id = Y_train[\"GalaxyID\"].tolist()\n",
        "test_id = Y_test[\"GalaxyID\"].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjw0EjUFGT01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_l = len(train_id)\n",
        "X_train = np.zeros((train_l, 224, 224, 3))\n",
        "i = 0\n",
        "for id in train_id:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  X_train[i] = X_full[name]\n",
        "  del X_full[name]\n",
        "  i+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzAX1TMGuM_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b4c3b7d7-d2eb-4e5e-efea-4b210ecb16ae"
      },
      "source": [
        "test_l = len(test_id)  \n",
        "X_test = np.zeros((test_l, 224, 224, 3))\n",
        "i = 0  \n",
        "for id in test_id:\n",
        "  name = 'images_training_rev1/'+str(id)+'.jpg'\n",
        "  X_test[i] = X_full[name]\n",
        "  del X_full[name]\n",
        "  i+=1\n",
        "  \n",
        "Y_train.drop(columns=[\"GalaxyID\"])\n",
        "Y_test.drop(columns=[\"GalaxyID\"])\n",
        "\n",
        "'''\n",
        "At the end of this cell we have four important variables, namely: \n",
        "X_train and X_test --> containing the training and testing images as lists of images.\n",
        "Y_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAt the end of this cell we have four important variables, namely: \\nX_train and X_test --> containing the training and testing images as lists of images.\\nY_train and Y_test --> containing the training and testing outputs for the images as pandas dataFrames.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxYYvELfm7Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the hyperparameters\n",
        "num_epochs = 500\n",
        "batch_size = 50\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0yvCB-exWf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the ResNet Architecture\n",
        "\n",
        "class ResNet:\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def identity_block(self, X, f_shape, n_filters, stage, block_name):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(f_shape, f_shape), strides=(1, 1), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def convolutional_block(self, X, f_shape, n_filters, stage, block_name, s=2):\n",
        "    '''\n",
        "    X -> Input tensor \n",
        "    f_shape -> Integer, denoting the shape of the middle filter\n",
        "    n_filters -> List, denoting the number of filters in each layer\n",
        "    stage -> Integer, denoting the name of the layer\n",
        "    block_name -> Denotes the name of the layer\n",
        "    s -> denoting the stride to be used\n",
        "    '''\n",
        "    \n",
        "    f1, f2 = n_filters\n",
        "    X_skip = X\n",
        "    \n",
        "    #1st component\n",
        "    #1st component\n",
        "    X = Conv2D(filters=f1, kernel_size=(f_shape, f_shape), strides=(s, s), padding=\"same\", name= \"resnet\"+str(stage)+block_name+\"_branch_2a\", kernel_initializer=glorot_uniform(seed=0))(X) \n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #2nd component\n",
        "    X = Conv2D(filters=f2, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name = \"batchnorm\"+str(stage)+block_name+\"_branch_2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Convolution for the shortcut\n",
        "    X_skip = Conv2D(filters=f2, kernel_size=(1, 1), strides=(s, s), padding=\"valid\", name= \"resnet\"+str(stage)+block_name+\"_branch_1\", kernel_initializer=glorot_uniform(seed=0))(X_skip)\n",
        "    X_skip = BatchNormalization(axis=3, name= \"batchnorm\"+str(stage)+block_name+\"_branch_1\")(X_skip)\n",
        "    \n",
        "    #Inserting skip connection\n",
        "    X = Add()([X, X_skip])\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    return X\n",
        "  \n",
        "  def ResNet18(self, input_shape=(224, 224, 3), classes=38):\n",
        "    '''\n",
        "    Defining the ResNet18 Architecture used\n",
        "    \n",
        "    Conv1 -> 7 X 7, 64, stride = 2, Output = (112 X 112)\n",
        "    \n",
        "    Conv2 -> 3 X 3 MaxPool, stride=2\n",
        "             [3 X 3, 64] * 2\n",
        "             \n",
        "    Conv3 -> [3 X 3, 128] * 2\n",
        "    \n",
        "    Conv4 -> [3 X 3, 256] * 2\n",
        "    \n",
        "    Conv5 -> [3 X 3, 512] * 2\n",
        "    '''\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    #Conv1\n",
        "    X = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name=\"conv1\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=\"batchnorm_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #Conv2\n",
        "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[64, 128], stage=2, block_name=\"b\")\n",
        "    \n",
        "    #Conv3\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[128, 256], stage=3, block_name=\"b\")\n",
        "    \n",
        "    #Conv4\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[256, 512], stage=4, block_name=\"b\")\n",
        "    \n",
        "    #Conv5\n",
        "    X = self.convolutional_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"a\", s=2)\n",
        "    X = self.identity_block(X, f_shape=3, n_filters=[512, 1024], stage=5, block_name=\"b\")\n",
        "    \n",
        "    #Final Dense Layers\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    #Create the model\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"ResNet18\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFn8ZdZceZ7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "87a6d1ff-f3e0-4d67-ce88-cdf9b8d0b081"
      },
      "source": [
        "#Initializing and Compiling the model\n",
        "Resnet18 = ResNet()\n",
        "model = Resnet18.ResNet18(input_shape=(224, 224, 3), classes=38)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "train_tensorboard = TensorBoard(log_dir=\"./logs/train\", histogram_freq = 0, write_graph  =True, write_images = True)\n",
        "test_tensorboard = TensorBoard(log_dir=\"./logs/test\", histogram_freq = 0, write_graph  =True, write_images = False)\n",
        "checkpointer = ModelCheckpoint(filepath='tmp/weights_resnet18.hdf5', verbose=1, save_best_only = True)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7BI7EYMJZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "8062e9f7-0f88-4a71-c95a-1a4f58093774"
      },
      "source": [
        "#Traing the model on the training data\n",
        "model.fit(X_train, Y_train, epochs = 20, batch_size = 32, verbose = 1, callbacks = [checkpointer, train_tensorboard])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 17069.5944 - acc: 0.9600\n",
            "Epoch 2/20\n",
            " 32/800 [>.............................] - ETA: 2s - loss: 84.6505 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 3/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 4/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 5/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 6/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 81.8365 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f550e52eac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qm6owX8OI8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4a205aea-96a3-46ca-94f0-98a174dc9f94"
      },
      "source": [
        "#Evaluating the data on the test set\n",
        "prediction = model.evaluate(X_test, Y_test, batch_size = 32, verbose = 1)\n",
        "print(\"Test Loss: \"+str(prediction[0]))\n",
        "print(\"Test Accuracy: \"+str(prediction[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 1s 5ms/step\n",
            "Test Loss: 80.57517470174761\n",
            "Test Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O9h5RAjiQra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}